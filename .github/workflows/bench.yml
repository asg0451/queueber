name: Benchmarks (Criterion)

on:
  push:
    branches: [ master ]
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  workflow_dispatch:

permissions:
  contents: write
  actions: read
  checks: write
  pull-requests: write

concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: true

jobs:
  criterion:
    name: Run Criterion benchmarks and track over time
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y capnproto jq libclang-19-dev

      - name: Set up Rust toolchain (nightly)
        uses: dtolnay/rust-toolchain@nightly
        with:
          components: clippy,rustfmt

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2
        with:
          cache-on-failure: true

      - name: Show rustc version
        run: rustc -Vv && cargo -V

      - name: Build benches
        run: cargo build --benches --locked

      - name: Run tests (sanity)
        run: |
          cargo test --all --locked --no-fail-fast
          cargo clippy --all-targets --all-features -- -D warnings

      - name: Run Criterion benches
        run: |
          # Run all benches; Criterion outputs to target/criterion
          cargo bench --all

      - name: Debug list Criterion outputs
        run: |
          echo 'Criterion estimates files:'
          find target/criterion -type f -name estimates.json -print 2>/dev/null || true
          echo 'Directory summary:'
          du -sh target/criterion || true

      - name: Summarize Criterion results -> JSON (ms, smaller is better)
        shell: bash
        run: |
          set -euo pipefail
          RESULTS=criterion-summary.json
          echo '[]' > "$RESULTS"
          shopt -s globstar nullglob
          declare -A picked
          files=(
            target/criterion/**/new/estimates.json
            target/criterion/**/estimates.json
            target/criterion/**/base/estimates.json
          )
          for f in "${files[@]}"; do
            [[ -f "$f" ]] || continue
            # Extract full bench id between target/criterion/ and (new|base|estimates.json)
            id=${f#target/criterion/}
            id=${id%/estimates.json}
            id=${id%/new/estimates.json}
            id=${id%/base/estimates.json}
            # Prefer earlier entries in files[] ordering
            if [[ -n "${picked[$id]:-}" ]]; then
              continue
            fi
            mean_sec=$(jq -r '.Mean.point_estimate' "$f")
            # Skip invalid/empty values
            if [[ -z "$mean_sec" || "$mean_sec" == "null" || "$mean_sec" == "" ]]; then
              continue
            fi
            # Convert seconds to milliseconds for readability
            ms=$(awk -v s="$mean_sec" 'BEGIN{printf "%.3f", s*1000}')
            tmp=$(mktemp)
            jq --arg name "$id" --argjson value "$ms" '. + [{"name":$name,"value":$value}]' "$RESULTS" > "$tmp"
            mv "$tmp" "$RESULTS"
            picked[$id]=1
          done
          echo 'Generated summary:'
          cat "$RESULTS"
          # Fail clearly if empty to aid debugging
          if [[ "$(jq 'length' "$RESULTS")" -eq 0 ]]; then
            echo 'No Criterion estimates were found. See previous debug step for files present.'
            exit 1
          fi

      - name: Store benchmark result (github-action-benchmark)
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Criterion
          tool: "customSmallerIsBetter"
          output-file-path: criterion-summary.json
          gh-repository: ${{ github.repository }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: benchmark-data
          comment-always: true
          alert-threshold: '200%'
          fail-on-alert: false

      - name: Upload Criterion raw output (artifact)
        id: upload_artifacts
        uses: actions/upload-artifact@v4
        with:
          name: criterion-output
          path: |
            target/criterion/**
            criterion-summary.json
          if-no-files-found: warn

      - name: Comment PR with artifact link
        if: github.event_name == 'pull_request'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          header: benchmark-artifact
          message: |
            Benchmark artifacts uploaded: criterion-output
            • Artifacts page: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
            • Summary JSON: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}